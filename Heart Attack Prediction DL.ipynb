{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b367996-2f07-4dc4-bfb7-fc919acb1263",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#importing the libraries:\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6b48024-266c-43fe-82e1-9fc700491c21",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#importing the dataset:\n",
    "df = spark.read.csv('/FileStore/tables/heart_attack_prediction_dataset.csv',header=True,inferSchema=True)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b105cb7c-dbbf-4798-aa1f-3f95153eece4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bca2b270-713c-443e-9dfe-6e63b119df21",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#creating a function to preprocess the data:\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def data_preprocessor(df):\n",
    "    #converting the df:\n",
    "    df = df.toPandas()\n",
    "\n",
    "    #splitting the bloodpressure column:\n",
    "    df['Systolic'] = df['Blood Pressure'].str.split('/',n=2,expand=True)[0].astype('int')\n",
    "    df['Diastolic'] = df['Blood Pressure'].str.split('/',n=2,expand=True)[1].astype('int')\n",
    "\n",
    "    #keeping required columns:\n",
    "    new_df = df.drop(columns=['Patient ID','Blood Pressure'],axis=1)\n",
    "\n",
    "    #splitting the columns into numerical and categorical:\n",
    "    num_cols = new_df.select_dtypes(include='number').columns.to_list()\n",
    "    cat_cols = new_df.select_dtypes(exclude='number').columns.to_list()\n",
    "\n",
    "    #preprocessing the data:\n",
    "    sc = StandardScaler()\n",
    "    sc_cols = sc.fit_transform(new_df[num_cols].values)\n",
    "    sc_df = pd.DataFrame(sc_cols,columns=sc.get_feature_names_out())\n",
    "    \n",
    "    ohe = OneHotEncoder(drop='first',handle_unknown='ignore',sparse=False)\n",
    "    ohe_cols = ohe.fit_transform(new_df[cat_cols].values)\n",
    "    ohe_df = pd.DataFrame(ohe_cols,columns=ohe.get_feature_names_out())\n",
    "\n",
    "    final_df = pd.concat([sc_df,ohe_df,new_df['Heart Attack Risk']],axis=1)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5fbae6c7-1f3b-4cbc-8924-63513e729e5c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = data_preprocessor(df)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29070718-fe26-471d-850a-e502c0152fb9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#splitting the data into train,val and test:\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = data.drop('Heart Attack Risk',axis=1)\n",
    "y = data['Heart Attack Risk']\n",
    "\n",
    "X_train,X_rem,y_train,y_rem = train_test_split(X,y,test_size=0.4)\n",
    "X_val,X_test,y_val,y_test = train_test_split(X_rem,y_rem,test_size=0.5)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25f2d430-e73e-4ffa-a146-fae0989507c7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#creating the model:\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "def create_model(hpo):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(int(hpo[\"dense_l1\"]),activation=\"relu\"))\n",
    "    model.add(Dense(int(hpo[\"dense_l2\"]),activation=\"relu\"))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5fb8eaa-c409-486d-b6ba-25ba3c145ee3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#setting the hyperparameters:\n",
    "from hyperopt import tpe,fmin,hp,SparkTrials\n",
    "\n",
    "def run_nn(hpo):\n",
    "    model = create_model(hpo)\n",
    "\n",
    "    #selecting the optimzier:\n",
    "    optimizer_call = getattr(tf.keras.optimizers,hpo[\"optimizer\"])\n",
    "    optimizer = optimizer_call(learning_rate=hpo[\"learning_rate\"])\n",
    "\n",
    "    #compiling the model:\n",
    "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                  optimizer=optimizer,\n",
    "                  metrics='accuracy')\n",
    "    history = model.fit(X_train,y_train,validation_data=[X_val,y_val],epochs=10)\n",
    "\n",
    "    #evaluating the model:\n",
    "    metric = history.history['val_loss'][-1]\n",
    "    return -metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "178ec47b-9e0b-4fb0-9b80-6d3fe3a76e76",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#setting up parameter space and training the model:\n",
    "space = {\n",
    "    \"dense_l1\" : hp.quniform(\"dense_l1\",10,30,1),\n",
    "    \"dense_l2\" : hp.quniform(\"dense_l2\",10,30,1),\n",
    "    \"learning_rate\" : hp.loguniform(\"learning_rate\",-5,0),\n",
    "    \"optimizer\" : hp.choice(\"optimizer\",[\"Adadelta\",\"Adam\"])\n",
    "}\n",
    "\n",
    "trials = SparkTrials(parallelism=4)\n",
    "\n",
    "best_hyperparam = fmin(\n",
    "    fn = run_nn,\n",
    "    space=space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=4,\n",
    "    trials=trials\n",
    ")\n",
    "\n",
    "best_hyperparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6f88e96-741d-4507-bf93-fcae41a5f0cb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#creating the final model with best hyperparams:\n",
    "import mlflow\n",
    "\n",
    "def create_model(best_hyperparam):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(best_hyperparam['dense_l1'],activation=\"relu\"))\n",
    "    model.add(Dense(best_hyperparam['dense_l2'],activation=\"relu\"))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "with mlflow.start_run(run_name=\"DL_Model_Heart_Attack\") as run:\n",
    "    mlflow.tensorflow.autolog()\n",
    "    model = create_model(best_hyperparam)\n",
    "\n",
    "    #selecting the optimzier:\n",
    "    optimizer_call = getattr(tf.keras.optimizers,\"Adadelta\")\n",
    "    optimizer = optimizer_call(learning_rate=best_hyperparam['learning_rate'])\n",
    "\n",
    "    #compiling the model:\n",
    "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                  optimizer=optimizer,\n",
    "                  metrics='accuracy')\n",
    "    mlflow.log_params(best_hyperparam)\n",
    "    history = model.fit(X_train,y_train,validation_data=[X_val,y_val],epochs=10)\n",
    "    \n",
    "    #evaluating the model:\n",
    "    metric = history.history['val_loss'][-1]\n",
    "    print(metric) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf2ccac2-9e15-4a01-9c1b-af4166650097",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "logged_model = 'runs:/16e526f07d2f47559ee513f6dc25dfa0/model'\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "# Predict on a Pandas DataFrame.\n",
    "preds = loaded_model.predict(X_test)\n",
    "for i in preds.index:\n",
    "    if preds[0][i] >= 0.5:\n",
    "        preds[0][i] = 1\n",
    "    else:\n",
    "        preds[0][i] = 0\n",
    "preds\n",
    "score = accuracy_score(preds,y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d0b1d9e-fc53-4ea9-9ebb-26720aa891cc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import flask\n",
    "from flask import Flask\n",
    "\n",
    "app = Flask(\"HeartPred\")\n",
    "\n",
    "@app.route(\"/\",methods=[\"GET\"])\n",
    "def welcome():\n",
    "    return \"Welcome to the Home page\"    \n",
    "\n",
    "if app == 'HeartPred':\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b245eb43-05d0-4884-a67d-18373b2ac2e8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Heart Attack Prediction DL",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
